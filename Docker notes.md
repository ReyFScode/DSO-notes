
# **Docker Guide**
Docker is a service that facilitates the creation of containers. Containers are lightweight, portable, configurable environments which are loosely isolated from the host machine; this allows them to run consistently across various environments. While containers are technically a virtualization technology they are NOT virtual machines (except in the case of windows containers running Hyper-V isolation, more on that later). Containers directly utilize the hosts OS kernel to run processes and share resources/hardware with the host system; VMs run their OS instances using an isolated virtual kernel and use hypervisors to emulate hardware/hardware interfaces.

**tldr;** Docker is used to create images/containers, which are configurable, lightweight, portable environments for dev/production use, while they are technically a virtualization technology, they are not VMs; they do not have anywhere near the level of isolation that a VM has.


---

# **Docker Core Concepts**
- **Docker Image:** A file containing source code, libraries, dependencies, tools, and other files necessary for an application/OS to run, all of those are bundled into something called layers; images are a combination of layers. Images serve as the basis for containers. 

- **Docker Container:** This is what docker is used to create, containers run on images. A Docker container image is a lightweight, standalone, executable package of software that includes everything needed to run an application: code, runtime, system tools, system libraries and settings. Containerized software will always run the same, regardless of the infrastructure. Containers isolate software from its environment and ensure that it works uniformly despite differences for instance between development and staging.

- **Docker Engine:** The core open-source containerization technology that enables the building and containerization of applications.
  
- **Docker Daemon:** The core of Docker Engine, a self-sufficient runtime that manages Docker objects like images, containers, networks, and storage. It listens for REST API requests and performs operations accordingly.

- **Docker Registry:** A server-side application that stores and distributes Docker images. Docker Hub is a popular cloud-based public registry, while private registries offer control over image storage and access.

- **Docker Volume:** File system mechanisms for storing data generated by running containers.

---

# **Essential Docker Commands**

**Core docker commands**
#### 1. Display Docker Version 
```bash 
docker -v
```
#### 2. Display Docker configuration info
```bash
docker info
```
#### 3. Docker inspect
```bash
#this command returns information about the configuration of a specified container
docker inspect [container_id_or_name]
```
#### 4. Docker exec
```bash
# we use this command to enter the terminal of a detached running container/run a command inside of it
docker exec -it [container_id_or_name] [command/shell to enter]

#example
docker exec -it Ubuntu_container bash #enters the bash terminal (via -it) of a container named Ubuntu_container, without -it this would do nothing because it would just run the bash command not connect to a terminal
docker exec Ubuntu_container free -h #runs the free -h command in the container and displays the command output
```
#### 5. List Installed Docker Images
```bash
docker image ls -a #specify -q for quiet list
```
#### 6. List All Docker Containers
```bash
docker ps -a #specify -q for quiet list
```
#### 7. Start Docker container
```bash
# Starts stopped container
docker start [container_name]
```
#### 8. Restart Docker container
```bash
# Starts stopped container/restarts running container
docker restart [container_name]
```
#### 9. Stop/remove Docker Container
```bash
# stops running docker container
docker stop [container_name]

#removes stopped container
docker rm [container_name]

#force removes a container (doesnt have to be stopped)
docker rm -f [container_name]
```
#### 10. Tag Docker Image
```bash
# sets image to use custom name & tag, often used before pushing a docker image to a registry
docker image tag OldName:OldTag NewName:newTag
```
#### 11. Pull Docker Image
```bash
docker pull imageName:tag
```
#### 12. Re-tag/Push Docker Image
```bash
# The command(s) used to push a docker image to a registry, requires you tag the image with the registry IP & port first, for this example we tag an image to push to a registry with an IP of 192.168.0.200, after tagging we push it
docker image tag ubuntu:latest 192.168.0.200:5000/RegistryUbuntu:customtag
docker push 192.168.0.200:5000/RegistryUbuntu:customtag
```
#### 13. Run Docker Container
We use `docker run` to create a container from an image. We can specify different flags to perform different actions/configurations for the container at instantiation. Docker run docs [here](https://docs.docker.com/reference/cli/docker/container/run/#publish)

```bash
docker run [-flags] [image_to_use]

Flag examples:
-d = specifies detached mode (container runs in the background).

-it = interactive terminal, keeps containers stdin open and binds container i/o streams to a terminal so you can interact with the container through a terminal session.

--name = allows you to assign a custom name to the container.

--rm = this flag will set it so that the container will be auto-deleted after it exits

-e = specifies environment variables for the container, you can designate specific variables by specifying something like -e "env-var=foo" or add a env var that exists on your host machine by just specifying the name, for example, -e "HOSTTYPE" will map the HOSTTYPE env var on the host to the container, but if hosttype already exists in the container it will not overwrite it so keep that in mind. Use a different -e for each assignment.

-p = allows you to map container ports to host ports, you specify it like this -p hostPort:containerPort, use a different -p for each mapping (e.g -p 8080:80 -p 50:51 maps host port 8080 to container port 80, and 50 to container port 51). Basically this means that services that are exposed on these container ports will also be exposed on your host machines ports e.g. a service with a mapping of 80:80 will serve data from port 80 in the container to localhost:80 on your host machine.

--net = assigns a network to the container

-v / --volume = mounts a volume (bind or named) to a container (more on volumes below).

--isolation process/hyperv = used to set the isolation level for windows containers (more on this below).

--restart = use to set a containers restart policy, common choices are 'always', 'on-failure', and 'unless-stopped', syntax is --restart [choice]

--entrypoint = sets a manual entrypoint for the container e.g --entrypoint '/bin/bash' will set bash as the default entrypoint, this is useful when you:
(1) have to specify a default command the container should run at instantiation you do this by specifying the entrypoint as one command and then appending the additional values at the end of the run command, for example:   "docker run -it --entrypoint '/bin/cat' test:image test.txt"    will use /bin/cat as the entrypoint and append test.txt to it (full comm: /bin/cat test.txt). That means this command will cat the contents of test.txt when the container is instantiated, once the command runs the container shuts down. You should only specify single commands in entrypoint e.g /bin/echo, /bin/bash, /bin/path. Additional commands / flags should always be passed at the end of the docker run command.
(2) specifying a shell as an entrypoint is kind of a hacky way to keep a container that keeps shutting down on you, due to a built-in entrypoint, alive; using this command in conjunction with -dit should keep it runing in the background and available for entry. e.g:   docker run -dit --entrypoint "/bin/bash" test:image  will override a built-in entrypoint and keep the container live.

--appending commands to the end of the run statement = you dont have to specify entrypoint, specifying entrypoint will ensure a certain command will always run whenever that container is started, but normally if you have a container that has no specified entrypoint and you need to specify a one off command you can just do something like: 'docker run ubuntu:latest /bin/echo "hello world"' and your container will pass the '/bin/echo "hello world"' command at runtime, return the output, and exit.

Docker run example:
# This command creates a container using the ubuntu:latest image, it is named test, it runs in the background (detached mode), it creates an interactive terminal that can be used to interact with the container, maps container port 8080 to host port 80, and mounts a volume called myVOL to /tmp in the container. It also specifies a restart policy of always and and an environment variable with a name of ENV1 that has a value of 123
docker run -dit --name test -p 80:8080 -v myVOL:/tmp --restart always -e ENV1=123 ubuntu:latest
# to enter this container we can use the below command (enters an interactive terminal that uses the bash shell):
docker exec -it test bash
```

**commands used to modify/interact with running containers**
#### 14. Docker copy
docs [here](https://docs.docker.com/reference/cli/docker/container/cp/)
```bash
# command used to copy a local file into a container or from a container to the host

docker cp ./some_local_file CONTAINER_NAME:/target_directory #copies some_file into the target_directory dir in the container

docker cp CONTAINER_NAME:/logs/log1.log /tmp #copies log1.log from /logs in the container to the /tmp dir on your local machine
```
#### 15. Docker update/rename
update docs: [docker container update | Docker Docs](https://docs.docker.com/reference/cli/docker/container/update/)
```bash
# rename will rename a running container
docker rename [container_name_or_ID] [new name]

# update can update SOME aspects of a running container, e.g. here we update a containers restart policy
docker update --restart unless-stopped [container_name]
# this is primarily used for updating resource limits, see the above docs for more info on docker update
```

#### 16. Create a new image from a container using commit
commit docs: [docker container commit | Docker Docs](https://docs.docker.com/reference/cli/docker/container/commit/)
```bash
# This will export a container with all its filesystem changes and settings to a new image, very useful for backups
docker commit [container_name/ID] [new_image_name:tag]
```



----


# **Docker Volumes**
Docker volumes are used to store and persist data generated by containers. There are two Main types: named volumes & bind mounts. Volumes can be shared among containers. Something very important to note, volumes overwrite the contents of the container directory with their contents.

- **Named Volumes:** Created with the `docker volume create` command, or if there is not volume already created, one will be created when specifying -v/--volume in the docker run command (and not using bind-mount syntax). You use volumes to retain changes to certain directories and to share data in certain directories with other containers (named volumes can be used by multiple containers) using the *-v* flag to specify the same or a new location for the volume to mount to. **!!** A non empty named volume will overwrite the directory contents of its mount point.

- **Bind mount:** Mounts a local directory into the container, any container-side changes to the bind mounted directory will be reflected on the host and vice versa (can also be used to overwrite specified file contents). bind mounts, like named volumes, can also be used by different containers refer to the above paragraph. **!!** A bind mount will overwrite the directory contents of its mount point.

- **Anonymous Volumes:** BONUS VOLUME!! Automatically created by Docker...sometimes, or created by specifying a directory and not mapping it in bind/named volume format. You can map anonymous volumes to containers to share data by specifying the name (just like when using a a named volume to share data). To my knowledge, there is no use case for these in a development/production front, best practices dictate that you use a named volume. Don't really worry about these.
#### Docker volume commands

#### 1. Display docker volumes (named/anonymous)
```bash 
docker volume ls 
```
#### 2. Create named docker volume
```bash
docker volume create [volume_name]
```

#### 3. Inspect  volume
```bash
docker volume inspect [volume_name] #Displays details about the volume
```

#### 4. Delete docker volume
```bash
docker volume rm [volume_name] #This command deletes a specific volume

docker volume prune #Deletes all unused docker volumes, can be used with a -f flag to force delete

docker volume rm $(docker volume ls -q) #Sometimes docker volume prune doesnt work, this command will 100% delete all unused docker voumes
```

#### Examples

- **Anonymous Volume Assignment:**
```bash
docker run -v /directory/in/container [image_name]
```

- **Named Volume Assignment:**
```bash
docker run -v name_of_volume:/container_location [image_name]

# if you have already created the volume with the `docker volume create command`, as long as you specify the name of the created volume, that volume will be used. If the volume hasnt been created, and this format is used a new named volume will be spun up.

```

- **Bind Mount Assignment:**
```bash
docker run -v "/FULL_PATH_TO/host_directory:/container_directory" [image_name]
# Loads /host_directory contents into /container_directory, any container-side changes to the bind mounted directory will be reflected on the host and vice versa. You must specify the FULL PATH to the dir on the host side, you can specify:  -v "$(pwd):/dir_in_container"   if you're inside the directory you want to mount, this will help make the command shorter (make sure you use "" for variable expansion, pwd is a linux & windows command that prints the present working directory, $() allows you to write the command output to a variable).
```

- **Bind Mount - overwrite file in container:**
you can overwrite a specific file in a container using a bind mount, NOTE: this will overwrite the contents of the file but the file will still be named the same in the container e.g. if you mount 1.txt on your host to 2.txt in the container, 2.txt will have the contents of 1.txt but the name will still be 2.txt.
```bash
docker run -v /host_directory/file.extension:/container_directory/file.extension:ro [image_name]
# :ro at the end specifies "read only", this means the container can't modify the file on its end, this is an optional flag
```

- **Volumes from flag**
using the --volumes-from flag we can create a container that has an exactly the same volumes from another e.g if container 1 has a named volume at /etc and a bind mount from some/dir to /tmp, if we specify this flag on container 2 it will have the same named volume at /etc and the same bind mount.
```bash
--container_1 has 2 volumes, a bind mount and a named volume. we use the flag on container_2 like so:

docker run -dit --volumes-from [container_1_ID] ...

Now container_2 has the same volumes in the same places as container_1
```

##### Best practice for backing up docker named volumes:
The best practice process for backing up docker named volumes is by mounting the volume to a new container using the `--volumes-from` flag, bind mount a host directory to backup data, and then tar the volume directory to the bind mount directory. (1) you don't have to make an new container but its best practice to ensure nothing goes wrong in the prod container (2) you need to remember what directory the volume is mounted on. There is a docker desktop extension you can use to simplify the process:
docker volume backup docs: [Volumes | Docker Docs](https://docs.docker.com/storage/volumes/#back-up-restore-or-migrate-data-volumes)
docker volume backup extension: [Back Up and Share Docker Volumes with This Extension | Docker](https://www.docker.com/blog/back-up-and-share-docker-volumes-with-this-extension/)


----


# **Docker Networks/Networking**
Docker provides a comprehensive networking abilities that allows containers to communicate with each other and with external networks. Docker networking enables  connectivity between containers, containers and their host, and between containers and external networks.

#### Docker network commands

#### 1. Display docker networks
```bash 
docker network ls
```
#### 2. Create docker network
```bash
docker network create -d [network-driver] [network-name]  #To create a new docker network you must assign it a driver to use and a name, if you dont specify a driver it will be bridge by default. Note that you cannot use the host driver because you cannot have more than one host network, more on drivers below
driver options =  -d bridge, host, ipvlan, macvlan, overlay, none=disables container networking
```
#### 3. Inspect docker network
```bash
docker network inspect [network-name] #Displays details about a specified network
```
#### 4. Delete docker volume
```bash
docker network rm [network_name] #This command deletes a specific network

docker network prune #Deletes all CUSTOM networks not in use

docker volume rm $(docker volume ls -q) #Sometimes docker volume prune doesnt work, this command will 100% delete all unused docker voumes
```
#### 5. Assign network to container
```bash
# use the --net flag in docker run
docker run --net=[network_name]
OR
docker run --net [network_name]
```

#### Docker Network driver types & details
1. **Bridge Networks:**
     - A docker bridge network creates a virtual bridge between the host and the container.
     - Containers connected to a bridge network can communicate with other containers on the same bridge network, but not other containers on other types of non-host network.
     - bridge docs: https://docs.docker.com/network/drivers/bridge/
    
2. **Host Networks**:
     - Only one allowed per docker host, because it binds directly to the host network.
    - Containers bypass Docker's virtual network and directly use the host's network interfaces (hosts IP, ports, etc.)
    - Containers on the host network can communicate with containers on any network, including bridge, IPvlan, or Macvlan networks, because they share the same network namespace as the host and bypass Docker's virtual networking.
    - This mode can provide better network performance but may lead to port conflicts.
    - host docs: https://docs.docker.com/network/drivers/host/

3. **Overlay Networks:
    - Overlay networks enable communication between containers across multiple Docker hosts or nodes in a cluster (basically is a bridge network for multi-host container clusters).
    - Docker Swarm and Kubernetes use overlay networks for container orchestration.
    - VXLAN (Virtual Extensible LAN) is commonly used to encapsulate overlay network traffic.
    - overlay docs: https://docs.docker.com/network/drivers/overlay/

4. **MacVLAN Networks**:
    - This is a type of network driver that operates at the Data Link Layer (Layer 2) of the OSI model
    - Macvlan allows Docker containers to have their own MAC addresses and appear as physical devices on the network.
    - This enables containers to communicate directly with other devices on the network.
    - Useful for scenarios where containers need to be treated as first-class citizens on the network.
    - MacVLAN docs: https://docs.docker.com/network/drivers/macvlan/

5. **IPvlan Networks**:
    - This is a type of network driver that operates at the Network Layer (Layer 3) of the OSI model.
	- Containers connected to IPvlan networks can communicate directly with other devices on the network without going through a bridge.
	- Users can define subnet ranges, gateway addresses, and other network settings for custom IPvlan networks.
	- Custom IPvlan networks offer flexibility and control over container networking.
	- IPvlan docs: https://docs.docker.com/network/drivers/ipvlan/

6. **Network Plugins**:
    - Docker supports third-party network plugins for integrating with various networking solutions.
    - Plugins enable Docker to work with SDN (Software-Defined Networking) platforms, cloud provider networks, and other networking technologies.
    - Examples include Calico, Flannel, Weave, and Cilium.

#### Basic Docker networking configurations/concepts

##### 1- Using the docker run `--add-host` Option
The `--add-host` option allows you to add custom entries to a container's */etc/hosts* file at runtime. This is useful for configuring custom hostname mappings for containerized applications. LINUX CONTAINERS ONLY. For example:

`docker run --add-host=myhost:192.168.1.100 my-container`
This command adds an entry mapping the hostname `myhost` to the IP address `192.168.1.100` within the container.

##### 2- Accessing `host.docker.internal`
In certain scenarios you may need containers to communicate with services running on the Docker host itself. Why do we need this? Imagine we have a container that is running on a host with no dhcp reservation (IP changes constantly), we have a program running in this container that needs to constantly query a service that lives on the host machine. Docker provides a special DNS entry `host.docker.internal` that resolves to the host's IP address from within a container. This allows containers to access services running on the host using a consistent hostname.

`curl http://host.docker.internal:8080`
This command, ran from within a container, would curl data from a service that lives on port 8080 on the Docker host.

Sometimes this may not resolve (albeit very rarely), If you notice `host.docker.internal` not resolving inside your container you can restart your container with this *--add-host* mapping in your container run command: 
`--add-host=host.docker.internal:host-gateway`

##### 3- Managing Gateway Settings
When containers are connected to Docker networks, they use the network's gateway for external communication. By default, Docker configures the gateway automatically. However, in some cases, you may need to customize the gateway settings, especially in complex network configurations or when using third-party networking plugins.
You can specify a custom gateway address when creating a Docker network:

`docker network create --gateway=192.168.1.1 my-network`

This command creates a Docker network named `my-network` with a custom gateway address of `192.168.1.1`.
Understanding and effectively managing gateway settings is crucial for ensuring proper network connectivity and routing within Docker environments.

##### 4- Docker socket
The Docker socket serves as the communication endpoint between Docker clients, like the CLI, and the Docker daemon. Typically located at `/var/run/docker.sock` on Linux systems, it facilitates interaction with the Docker daemon. 
Now, in scenarios where Docker needs to be run within Docker (I know Inception right?), the Docker socket must be mounted using a bind mount, like so:  
```docker run -v /var/run/docker.sock:/var/run/docker.sock```
NOTE: for windows containers docker uses named pipes for communication, so to run docker in docker on windows the mount would look something like this: 
`docker run -v \\.\pipe\docker_engine:\\.\pipe\docker_engine`

However, it's crucial to note that exposing a container or any resource with a Docker socket mount in a production environment is a severe security risk. In such cases, attackers gaining access to the container could exploit this vulnerability for escalation or pivot attacks. Essentially, they could gain unauthorized access to the locally installed Docker instance or, with minimal effort, infiltrate the host machine itself. Exercise extreme caution and consider security implications carefully before employing Docker socket mounts in production environments.



---


# **Dockerfile basics**
Dockerfiles act as essential tools for building custom Docker IMAGES, providing a streamlined process for constructing tailored environments tailored to specific applications or services.
For example, imagine a scenario where an application requires a Linux environment with precise selection of packages installed inside. Instead of starting from a base Linux image and manually configuring it through docker exec/docker cp, Dockerfiles allow us to begin with a base Linux image aligned with the desired distribution. Through the Dockerfile, we can then specify the installation of necessary packages and incorporate the proprietary application directly into the image. The resulting image provides a portable, pre-configured environment perfectly suited for executing the application. This eliminates the need for extensive manual configuration steps. This approach streamlines the process, making it easier to replicate, migrate, and deploy applications seamlessly.

##### Basic Dockerfile Commands
- **FROM:** Specifies the base image for the new image.
- **SHELL:** Specifies the shell to use for the dockerfile configurations
- **COPY:** Copies files from the host to the image
- **RUN:** Executes commands in shell form.
- **ENTRYPOINT:** Whatever you put here will automatically execute when the container is started (only one per dockerfile).
- **CMD:** Provides default arguments for the ENTRYPOINT instruction (only one per dockerfile), can also function as an entrypoint. 
- **WORKDIR:** Sets the working directory for any RUN, CMD, ENTRYPOINT, COPY, and ADD instructions that follow it in the Dockerfile.
- **ENV:** Sets environment variables.

##### Dockerfile example
Note - Dockerfiles 99.9999% of the time should be named Dockerfile
```Dockerfile
# Use the official Ubuntu:latest image as the base
FROM ubuntu:latest

WORKDIR /app
# Copy a file from the host to the image workdir (/app)
COPY ./app_dir/app.py .

# Run a command to configure the image
RUN apt-get update && apt-get upgrade -y && apt-get install -y python3

# Set the entry point for the container
ENTRYPOINT ["python3", "app.py"]

# Provide additional arguments for the entry point
CMD ["--debug"]

#so overall this dockerfile creates an image with a file called app.py copied in, and configures the image so that whenever a container is created from it it will automatically run this command: python3 app.py --debug
```
For more commands, refer to the [Dockerfile Cheat Sheet](https://kapeli.com/cheat_sheets/Dockerfile.docset/Contents/Resources/Documents/index).

**Command(s) to create image from a dockerfile**
```bash
#navigate to the directory that contains your Dockerfile and run:
docker build . -t [desired_image_name:desired_image_tag]

# If you have a dockerfile that ISNT named Dockerfile e.g. something like dockerfile-test you would use the -f flag like this:
docker build . -f [dockerfile-name] -t [desired_image_name:desired_image_tag]
```

**Quick clarification on `CMD` vs `ENTRYPOINT`:**
This can be confusing so here's a really simplified answer to help you, `ENTRYPOINT` is used to define the primary executable of the container, with every component of the command spaced and in quotes ,e.g. *"command", "Command2"* with `CMD` is used to provide default arguments or additional commands to the entrypoint. If you need to run a command that doesnt change at instantiation entrypoint is going to be what you need to use, you dont have to use CMD unless you want flags that are overridable at run. (try this out!):
``` Dockerfile
# Use a base image 
FROM ubuntu:latest 

# Set the default executable using ENTRYPOINT, each spaced term needs to be in "" seperated by a , e.g. ["/bin/bash", "-c"] to call a specific bash command
ENTRYPOINT ["/bin/echo", "Hello"] 

# Set default arguments using CMD 
CMD ["World!"]

# Name this Dockerfile and build it using docker build . -t test:img, now run a container with it using docker run --name test test:img
```
This command literally passes the command: */bin/echo Hello 'World'* command at runtime, notice that the part in CMD has added single quotes around it, this is what we mean by supplemental arguments. It is overridable because if you do *docker run --name test test:img bob* it will output "Hello bob" instead of "Hello World!"


View it like this: if we needed to run a command like mysqld we would need to first invoke the bash executable and pass a command flag through entrypoint, the actual mysqld would be in quotes after that: */bin/bash -c "mysqld"*
the */bin/bash -c i*s the entrypoint, the additional command components e.g mysqld is the CMD. If we dont need this command to change we could just lump it all into entrypoint.


NOTE: if entrypoint is passed a command with spaces it will treat it like cmd and add single quotes:
```
FROM ubuntu:latest
ENTRYPOINT ["/bin/bash", "-c", "hostname -i ; ls /proc ; /bin/bash"] 

```
In this example the command passed at instantiation is: */bin/bash -c 'hostname -i ; ls /proc ; /bin/bash'* this means that if we run the container with -it we will get the container IP, the contents of the proc directory, and since we end with /bin/bash a terminal we can enter into (also allows for detached mode). since there are spaces in the entry after -c it is passed in single quotes.

#clean_this_up_make_explanation_better^

##### Dockerfile Multistage builds
Multi-stage builds in Docker allow you to create smaller, more efficient Docker images by using multiple build stages within a single Dockerfile. Each stage can have its own set of instructions and dependencies, and artifacts from one stage can be selectively copied to subsequent stages. This is particularly useful for compiling source code, building binaries, and ensuring that only necessary files are included in the final image.
here's a simplified example:
```Dockerfile
# Stage 1: Build Environment
FROM ubuntu:latest AS build-stage 
# Install build tools (e.g., Maven, Gradle)
# Copy source code from host to image
# Build commands (e.g., compile, package)

# Stage 2: Runtime environment
FROM ubuntu:latest AS final-stage  
#  Copy application artifacts from the build stage (e.g., JAR file)
COPY --from=build-stage /path/in/build/stage /path/to/place/in/final/stage
# Define runtime configuration (e.g., CMD, ENTRYPOINT) 
```
multistage build docs: [Multi-stage builds | Docker Docs](https://docs.docker.com/guides/docker-concepts/building-images/multi-stage-builds/)

**Use case for multistage builds:** 
In a CI/CD pipeline for Docker-based applications, a multistage build process is utilized. The CI system triggers builds upon code changes, executing a Docker build defined in the pipeline. the pipeline writes/utilizes a multistage build DF to compile the application and create a lightweight Docker image. The resulting image, tagged with a version, is archived as a `.tar` artifact. In the CD pipeline, the artifact is deployed to various environments, leveraging the optimized Docker image for efficient deployment



---


# **Docker Compose**
Docker Compose is an orchestration tool used for defining and running container applications. Compose files use YAML format as configuration files. this is especially helpful when you have multiple containers that you need to be able to spin-up/down with one command.

##### Basics:
Lets say you have these two docker run commands: 
`docker run -d -p 8080:80 -v $(pwd)/html:/usr/share/nginx/html nginx:latest`
&
`docker run  -d  -v TestVol:/tmp --restart='always' ubuntu:latest

This docker compose file allows you to specify the configurations for both containers, this provides a portable template to spin them up with a single command. These files are yaml and as such much be formatted to yaml specifications. At a minimum you need a services section populated with a service name label, an image to use.

NOTE: these files are always named: docker-compose.yml

```yaml
version: '3.8' #optional line but usually good to include, specifies compatibility

services: #section to declare services, you must include this

  nginx: #label for service 1, configurations below
	container_name: c1 #container name
    image: nginx:latest #specifies image name to use for the service
    environment: #creates an environment variable in the container, here we create ENV_VAR with the value of somevalue
      - ENV_VAR=somevalue 
    ports: #specifies ports to map, here 8080 on the host is mapped to 80 in the container
      - "8080:80"
    volumes: #specifies a volume (bind mounts the local /html dir to /usr/share/nginx/html in the container)
      - ./html:/usr/share/nginx/html
	networks: #specifies a network to use for the container
	  - newnet

  ubuntu: #label for service 2, configurations below
	container_name: c2
    image: ubuntu:latest
    restart: always # restart policy
    entrypoint: /bin/bash #specifies the entrypoint for the container
    command: test.sh # specifies the commands to be run in the container at runtime, will execute after entrypoint, e.g. here we have /bin/bash test.sh as the command that will run at instantiation, this is the same as CMD in a dockerfile, pretty much interchangeable with entrypoint.
    volumes: # specifies volume (named volume)
      - TestVol:/tmp

volumes: # to use named volumes we must declare them in a section at the bottom
  TestVol:

networks: # to use networks we must declare them in a section at the bottom, we can specify the driver or it defaults to bridge
  newnet:
   driver: ipvlan

```
To spin up containers using this file, navigate to the the directory in which it exists, run:
`docker compose up -d (omit -d if you dont want them to run in the background)
To tear the containers down, navigate to the dir again and run:
`docker compose down -v (this command destroys named volumes associated with the containers, to preserve volumes omit the -v)`

For more information:
- [Docker Compose Tutorial](https://www.simplilearn.com/tutorials/docker-tutorial/docker-compose)
- [Docker Compose Documentation](https://docs.docker.com/compose/gettingstarted/)

##### Using variables with docker-compose:
To reference variables in a Docker Compose file, you can create a .env file in the directory where your docker-compose.yml lives. Docker compose will look for a .env when you execute the up command and populate variables specified with ${SOME_VAR}. 

``` ENV
# file called .env

HOST_VALUE1=hello
HOST_VALUE2=world!
```

``` YAML
# docker-compose.yml
services:
	someservice:
	  image: ubuntu:latest
	  command: "/bin/echo '${HOST_VALUE1} ${HOST_VALUE2}'"
# this will output "hello world!" when the 'docker-compose up' command is run
```

##### Some additional compose concepts/tricks:

###### 1- Specify a Dockerfile as the image to use
you can specify your Dockerfile as an image to build from and use in a docker-compose file like this: 
``` YAML
services:

  container_1:
    image: built-img:latest #this is optional, if you specify "image" in conjuction with a build step the built image will take the image name, if you dont specify this the built image will be auto-named
    build: #Specifies that the compose file should build the image to use
      context: ./ #specifies the path to the dockerfile (here we are implying it is in our current working directory)
      dockerfile: Dockerfile-test #name of the dockefile to use
    container_name: test_img
    ports:
      - 8000:8000
```

###### 2- docker compose container keeps shutting down
The first thing you should try is add `stdin_open: true` & `tty: true` to the compose service that's shutting down, this is equivalent to the -i flag in docker run and should keep it open. If that doesn't work you can do a hacky little trick to keep containers from shutting down when created via docker compose, sometimes the *entrypoint /bin/bash* keep-alive trick doesn't work for docker-compose, but if you add:
`entrypoint: /bin/tail -F anything` (yes, actually write anything) 
to the service section the container should stay open for exec sessions (will only work for Linux based images).



----


# **Docker Daemon overview/configuration (dockerd)**
The Docker daemon (Dockerd) is a background process responsible for managing Docker objects like images, containers, networks, and volumes. It exposes a REST API for interaction, handles container lifecycle (creation, start, stop), manages image caching and pulling, and enforces container isolation and security. Configuration settings for Dockerd, such as network configurations and storage drivers, can be defined in the `daemon.json` file.

##### Daemon.json configuration options: 

**1- specify insecure registries / nondistributable artifacts to allow pushes/pulls from local registries**
- insecure registries are docker registries (often locally hosted) that use http vs https. Docker will not allow you to pull/push images from/to these registries unless they are registered as trusted in the daemon.json.
- Nondistributable artifacts are Docker images or layers that Docker cannot distribute to other nodes in a swarm. You will also need to mark these to allow them to be pushed to registries.
You can accomplish this by adding these two lines to the daemon.json (for this example our registry is hosted at 192.168.0.100:5000):

``` JSON
{
  "insecure-registries": ["192.168.0.100:5000"],
  "allow-nondistributable-artifacts": ["192.168.0.100:5000"]
}
# adding these lines to the daemon json file will allow us to push and pull images unrestricted from a registry hosted at 192.168.0.100:5000
```

**2- configure universal default logging through the daemon.json**
By default (unless you configure the containers to use a different one) containers use the docker json-file logging driver. 
you can specify a different default logging driver through the daemon.json with this line:
```JSON
{
  "log-driver": "local"
}
```
The above example sets the default logging driver to be the local driver
logging driver options: [Configure logging drivers | Docker Docs](https://docs.docker.com/config/containers/logging/configure/#supported-logging-drivers)



----


# **Docker swarm**
Docker Swarm is Docker's native clustering and orchestration tool, designed to manage a cluster of Docker hosts and deploy containerized applications at scale. 

##### Docker swarm terms:
1. **Node**: A physical or virtual machine that is part of the Docker Swarm cluster. Nodes can be either manager nodes or worker nodes.
2. **Manager Node**: A node in the Docker Swarm cluster that runs the Swarm management components. Manager nodes are responsible for orchestrating the deployment and scaling of services, handling node membership changes, and managing the cluster state.
3. **Worker Node**: A node in the Docker Swarm cluster that runs the tasks (containers) associated with services deployed in the cluster. Worker nodes do not participate in the management of the cluster but execute tasks as directed by the manager nodes.
4. **Service**: A declarative definition of a containerized application or microservice in Docker Swarm. A service specifies the desired state of the application, including the container image, number of replicas, network configuration, and other parameters.
5. **Task**: An instance of a container running on a worker node in Docker Swarm. Tasks are created based on the service definition and are managed by the Docker Swarm scheduler.
6. **Replica**: A copy of a service task running on one or more worker nodes in Docker Swarm. The number of replicas defines how many instances of the service should be running concurrently.
7. **Overlay Network**: A virtual network created by Docker Swarm for communication between containers running on different nodes in the cluster. Overlay networks provide multi-host container communication without requiring external dependencies.
8. **Quorum**: The minimum number of manager nodes required to maintain consensus and perform cluster management operations in Docker Swarm. Quorum ensures the availability and consistency of the cluster state, even in the event of node failures or network partitions.

##### Docker swarm commands:
``` bash

docker swarm init = creates a docker swarm deployment, adds the host that the command is run on as a manager node

docker swarm join --token [token] [manager_IP]:2377 = you will get this command provided when you initialize a swarm, this command joins a node to the swarm as a worker

docker swarm leave -f = removes a node from the swarm

docker info | grep -i 'swarm' = command to determine if the node is part of a swarm

---------- node/service commands cant be run except on a swarm manager ------------

docker service create [service_name]
 = creates a service to be run on the swarm (similar to a docker run command, you can use the same flags)

docker service rm [service_name] = removes a created service

docker node promote [hostname/ID] = promotes a joined worker to manager status

docker node demote [hostname/ID] = demotes a joined manager to worker status

docker node ls = displays node information

docker node ps [hostname/ID] = displays tasks running on a node, can be run with just docker node ps if you want to see the services running locally
```
-swarm command cheat sheet: [Docker swarm cheat sheet - Kernel Talks](https://kerneltalks.com/virtualization/docker-swarm-cheat-sheet/)
--Compose with swarm is called  'deploying a stack', guide here: [Deploy a stack to a swarm | Docker Docs](https://docs.docker.com/engine/swarm/stack-deploy/)

##### Docker Swarm concepts/use-cases:

**1) Use case - Swarm vs K8s**: 
K8s is the optimal container orchestration and scheduling utility, no way around it. Swarm is good for small/mid-size production/development deployments and makes creating container clusters much easier than K8s does, but for large scale production deployments K8s is the way to go due to it being FAR more powerful and configurable.

**2) Shared storage among swarm containers:**
The best way to ensure that swarm containers have read/write access to the same pool of data is the use a NFS and mount it into the service via a bind mount.

**3) Networking in swarm**
If you don't specify an overlay network when creating the service it will default to using the hosts default bridge network, that means that service containers wont be able to perform cross-node communication, you must specify an overlay network to allow swarm cross-node communication.

##### Creating a Docker Swarm:

You must start by ensuring these ports are open on all the swarm nodes:
- Port `2377` TCP for communication with and between manager nodes
- Port `7946` TCP/UDP for overlay network node discovery
- Port `4789` UDP (configurable) for overlay network traffic

- you can use this command on most Debian based distros: `ufw allow 2377/tcp && ufw allow 7946/tcp && ufw allow 7946/udp && ufw allow 4789/tcp`
- Or this command on redhat based distros: `sudo firewall-cmd --zone=public --add-port=2377/tcp --permanent && sudo firewall-cmd --zone=public --add-port=7946/tcp --permanent && sudo firewall-cmd --zone=public --add-port=7946/udp --permanent && sudo firewall-cmd --zone=public --add-port=4789/tcp --permanent && sudo firewall-cmd --reload
`

1. **Initialize a Swarm:** To create a new Docker Swarm, you can initialize it on a node using the `docker swarm init` command:
    
    `docker swarm init`
    
    This command initializes the current node as the manager node of the Swarm.
    
2. **Joining Nodes to the Swarm:** Other nodes can join the Swarm as worker nodes or additional manager nodes by running the command provided by the `docker swarm init` output on those nodes. For example:
    
    `docker swarm join --token <SWARM_TOKEN> <MANAGER_IP>:<MANAGER_PORT>`
    
    Where `<SWARM_TOKEN>` and `<MANAGER_IP>:<MANAGER_PORT>` are obtained from the `docker swarm init` command output.
    

**Managing Services**
Once the Swarm is created, you can deploy services to it. Services define the desired state of an application and how many replicas of each container should be running. Here's an example of deploying a ubuntu service to a Docker Swarm:

`docker service create --name ubuntu-service --replicas 3 ubuntu:latest`

This command creates a service named `my_service` with three replicas that will be distributed logically across the swarm, using the Docker image `my_image`.

#add stack dockerfiles to sevice, and how to declare runtime args in service create

----


# **Deep-dive topics**

##### 1) Containerd vs. Docker, what on earth is containerd?
In your docker journey you will likely hear the term containerd, but oftentimes its a fleeting reference with little explanation, here we are gonna learn exactly what this is and how it relates to docker.

what is containerd?
Containerd is a runtime (a piece of code that allows the program to interact with the computing resources it needs to work) that is specifically built to run containers. "In 2017 Docker pulled its core container runtime into a standalone project called containerd and donated it to the Cloud Native Computing Foundation (CNCF).", Containerd has since become a industry standard container runtime noted for its robustness, efficiency, and power. "A key component of containerd’s robustness is its default use of [Open Container Initiative](https://opencontainers.org/) (OCI)-compliant runtimes. By using runtimes such as [runc](https://github.com/opencontainers/runc) (a lower-level container runtime), containerd ensures standardization and interoperability in containerized environments. It also efficiently deals with core operations in the container life cycle, including creating, starting, and stopping containers".

How does containerd interact with docker? 
lets say you initiate a docker run command, dockerd (the docker daemon) starts by parsing the run command, and based on the data taken from the parse, handle things like pulling images/validating the command. After the image is pulled and the command data has been validated dockerd shifts control to containerd. "Next, containerd will set up the container environment. This process includes tasks such as setting up the container file system, networking interfaces, and other isolation features. Containerd will then delegate running the container to runc using a shim process. This will create and start the container."
*all quotes from: [HERE]([containerd vs. Docker | Docker](https://www.docker.com/blog/containerd-vs-docker/))*

##### 2) What exactly are image layers?
docs here: [Understanding the image layers | Docker Docs](https://docs.docker.com/guides/docker-concepts/building-images/understanding-image-layers/)

Every image layer is a set of filesystem changes, layering is achieved through content-addressable storage and union filesystems (e.g. each layer is downloaded into a location on the filesystem, they are then stacked on top of each other to create the final image

##### 3) Windows containers: Hyper-V vs. process isolation
docs: [Isolation modes | Microsoft Learn](https://learn.microsoft.com/en-us/virtualization/windowscontainers/manage-containers/hyperv-container)

Windows containers are a little funky, they run in one of two modes: Hyper-V or process isolation. 

- **Hyper-V isolation** is when the container runs in a lightweight virtual machine on the windows host, this provides very strong isolation (container has its own kernel instead of sharing), but because of the stronger isolation the performance is lessened. 
- **Process isolation** is when the container essentially functions like a standard container directly leveraging the hosts kernel for processes/resources, because of the direct connection to the kernel the performance is greater than Hyper-V.

As long as virtualization is enabled on the windows host the host can run containers using Hyper-V isolation, to run containers using process isolation the kernel version of the container must match the host kernel version e.g. if your windows kernel is 20H2 you must use a windows image with a tag of 20H2. You switch between these modes by passing the run flag *--isolation*, example:
`docker run --isolation=hyperv`   OR   `docker run --isolation=process`



---
# **Additional Resources**

- [Docker Official Documentation](https://docs.docker.com/reference/)
- [More Docker Tutorials and Information](https://docs.docker.com/)
